{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93cd0ac2-2836-455a-ab88-ceca885a80e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SDF and Gaia - a new world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb50ea-c44a-4f4b-857e-bfeb4d349899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For rendering code snippets, SVG\n",
    "from IPython.display import HTML, Code, SVG\n",
    "\n",
    "import pprint\n",
    "\n",
    "# A hack to get Code syntax highlighting to work in Jupyterlab\n",
    "# https://github.com/ipython/ipython/issues/11747#issuecomment-528694702\n",
    "def display_source(code, language : str = \"python3\", style=\"material\"):\n",
    "    def _jupyterlab_repr_html_(self):\n",
    "        from pygments import highlight\n",
    "        from pygments.formatters import HtmlFormatter\n",
    "\n",
    "        fmt = HtmlFormatter(style=style)\n",
    "        style_outer = \"<style>{}\\n{}</style>\".format(\n",
    "            fmt.get_style_defs(\".output_html\"), fmt.get_style_defs(\".jp-RenderedHTML\")\n",
    "        )\n",
    "        return style_outer + highlight(self.data, self._get_lexer(), fmt)\n",
    "\n",
    "    # Replace _repr_html_ with our own version that adds the 'jp-RenderedHTML' class\n",
    "    # in addition to 'output_html'.\n",
    "    Code._repr_html_ = _jupyterlab_repr_html_\n",
    "    return Code(data=code, language=language)\n",
    "\n",
    "# Note: this code assumes real_world environment is sourced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa7a24f-d865-4a87-90e8-e99451f5c5fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unified World Model\n",
    "\n",
    "We want a single modular description format that can naturally describe the visual, physical and logical aspects (e.g. base configuration, virtual walls) of a complete robot line and all relevant objects for both real and simulated systems. This will allow us to have a single place where we can store this information (reducing complexity and error surface) and maximize reuse of tooling and assets.\n",
    "\n",
    "Our current solution is far from unified:\n",
    "\n",
    "- RobotPlanningScene with simple blocky parts we care about for (planning) collision checking.\n",
    "- Robot URDF.xacro + SRDF + EI Description\n",
    "- No concept of a \"world\" - everything expressed in \"the\" robot's base frame. \n",
    "- Inflexible, brittle, not scalable (e.g. robots on slides, multiple actuatable models in a world, external sensors, tooling to visualize/query all geometric information).\n",
    "\n",
    "## SDF\n",
    "\n",
    "For the Simulation stack we need to represent the world, along with all properties we care about. The format it uses (on disk) is [SDF](http://sdformat.org/) (Simulation Description Format). It is a powerful format for describing models, frames, and how they compose into worlds. Under active development and used by multiple teams ([OSRF](https://www.openrobotics.org/), [Drake](https://drake.mit.edu/)). \n",
    "\n",
    "We are transitioning to using SDF for describing our real world systems. Mixed Palletizing Bot will be the first application to use SDF from the ground up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f977425-d1e3-4829-9704-8140e0c9ee99",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SDF Examples\n",
    "\n",
    "#### A simple world\n",
    "\n",
    "Worlds are formed by the composition of frames and models.\n",
    "\n",
    "A bare bones example of a world with one model and one explicit frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc0b71-7fbb-4d66-8142-f3ec59aa4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_source(\"simple_world.sdf\", language=\"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b382310-32dc-499b-abde-bb701f843f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --no-raise-error\n",
    "# Visualize it in GV - you can also spin up an ignition instance, but that's much slower :)\n",
    "rosrun gaia gv simple_world.sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f86db12-2ec5-468a-8641-f9e55cc99f22",
   "metadata": {},
   "source": [
    "Points of attention:\n",
    "\n",
    "- A World composes a collection of models and frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5cc6a1-84f3-427c-aa39-92ee1fee8705",
   "metadata": {},
   "source": [
    "#### The anatomy of a model\n",
    "\n",
    "Let's look at a more interesting model with links and joints. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535282d-bdde-4da9-8af5-1b474691c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_source(\"model_with_joints.sdf\", language=\"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb6ef6-f7f9-4543-a1b4-e069c229873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --no-raise-error\n",
    "# Visualize it in GV\n",
    "rosrun gaia gv model_with_joints.sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630cbd1d-0da9-4cb4-a42c-72ce7e396895",
   "metadata": {},
   "source": [
    "#### A realistic example: Mixed Palletizing Bot dev cell\n",
    "\n",
    "Let's look at the Mixed Palletizing Bot dev cell world for a real world example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f4ab2-d059-499f-8861-238780a50f65",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Atlas contains SDF worlds and models\n",
    "from atlas.resolvers import resolve_sdf_world_path\n",
    "\n",
    "mpb_dev_cell_sdf_path = resolve_sdf_world_path(\"mpb_dev_cell.sdf\")\n",
    "\n",
    "display_source(mpb_dev_cell_sdf_path, language=\"xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572a1fdc-bb43-48e9-b980-0f6976431a66",
   "metadata": {
    "tags": []
   },
   "source": [
    "Some points of attention:\n",
    "\n",
    "- Includes and `model://` \n",
    "- Workspaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d703a-161d-4a31-8c28-5a6ef067405b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash --no-raise-error -s \"$mpb_dev_cell_sdf_path\"\n",
    "# Visualize it in GV\n",
    "rosrun gaia gv $1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd78fc-2702-429b-91ac-19cab86b7eeb",
   "metadata": {},
   "source": [
    "### Vicarious custom SDF extensions\n",
    "\n",
    "We have a few custom elements in SDF to deal with information like \"workspaces\" and \"planning volumes\" (see also the MPB visualization above).\n",
    "\n",
    "You can read more about them here:\n",
    "\n",
    "[Vicarious custom SDF extensions](http://docs.corp.vicarious.com/master/common/sdf/doc/user/custom_sdf_elements.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf1f4ac-bbdc-45ee-9bf6-817bf8418459",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### What about URDF(.xacro)?\n",
    "\n",
    "[URDF](http://wiki.ros.org/urdf) (Universal Robot Description Format) is the format we currently use to represent robot models. It is strictly less powerful than SDF: anything that can be expressed in URDF can be expressed in SDF, but not vice versa. \n",
    "\n",
    "We will move to using SDF robot models as the ground truth, and generate URDF models on the fly, where needed (e.g. RPS, KDL).\n",
    "\n",
    "External cameras now (hackily) defined in robot models will move to the `<world>` as stand alone `<model>`s.\n",
    "\n",
    "We aim to complete the switch to SDF for all suction robots in 2021-Q3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf7e0e-1546-42b0-8bf6-9d0351cf763c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gaia \n",
    "\n",
    "Gaia is an in-house solution for representing (robot) models and frames, and it can load SDF. It comes with a handy viewer `gv` which you already saw in action. It is designed to be flexible (quickly add new information you want to represent) and scalable (it can work for entire robot lines).\n",
    "\n",
    "The current use is to get information about the world that is statically known (e.g. where the BLB is in the robot base frame) for simplifying app configuration. We are working on extending it to deal with dynamic information (e.g. joint angles, pose detections) and show a globally consistent world view.\n",
    "\n",
    "\n",
    "### Demo - exploring Mixed Palletizing Bot dev cell \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e3bbb-afdf-4846-a53a-6378a2c97aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaia.gaia import Gaia\n",
    "\n",
    "# Load the world\n",
    "world = Gaia(mpb_dev_cell_sdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be9372-3caf-4905-9b61-2a440585e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What (top level) models does it have?\n",
    "\n",
    "world.get_model_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f24985a-3cd7-4063-a9c4-67e66fd8cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting transforms - works for any implicit (links, visuals, etc.) or explicit <frame>\n",
    "robot_in_world = world.get_transform(source_frame=\"main_arm/arm/base_link\")\n",
    "print(robot_in_world)\n",
    "\n",
    "# Everything works with scoped paths, and these directly follow the SDF model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9b545-6114-44e9-99a8-4d564db6d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is the pallet-right in arm's frame?\n",
    "pallet_right_in_robot =  world.get_transform(source_frame=\"pallet-right\", target_frame=\"main_arm/arm/base_link\")\n",
    "print(pallet_right_in_robot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed9b78-338d-424d-87ad-65d31232e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get workspace geometry (scoped path into a model - link - visual)\n",
    "\n",
    "workspace_shape = world.get_geometry_shape(\"conveyor-workspace/body/workspace\")\n",
    "workspace_in_world = world.get_transform(\"conveyor-workspace/body/workspace\")\n",
    "\n",
    "print(workspace_shape)\n",
    "print(workspace_in_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc940d0-141d-4b32-ad9b-a427c96a617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get joint angles for any actuatable model\n",
    "\n",
    "# By convention, \"the\" robot is called \"main_arm\"\n",
    "robot_joint_positions = world.get_model_joint_positions(\"main_arm\")\n",
    "pprint.pprint(robot_joint_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb12d3f-a479-43e5-a932-1eaf88d4a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set them. You can provide a nested model path as well. \n",
    "# Only need to provide the joints you want to set.\n",
    "world.set_model_joint_positions(\"main_arm/arm\", [('shoulder_pan_joint', 1.31)])\n",
    "\n",
    "\n",
    "robot_joint_positions = world.get_model_joint_positions(\"main_arm\")\n",
    "pprint.pprint(robot_joint_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1bd6d-442e-4dd7-b881-f4e555eeb5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of course, transforms reflect moving models. Gaia guarantees a consistent view.\n",
    "\n",
    "pallet_left_in_gripper = world.get_transform(source_frame=\"pallet-left\", target_frame=\"main_arm/arm/gripper_tip\")\n",
    "\n",
    "print(\"Before move \", pallet_left_in_gripper)\n",
    "\n",
    "\n",
    "world.set_model_joint_positions(\"main_arm/arm\", [('shoulder_pan_joint', 1.)])\n",
    "\n",
    "\n",
    "pallet_left_in_gripper = world.get_transform(source_frame=\"pallet-left\", target_frame=\"main_arm/arm/gripper_tip\")\n",
    "\n",
    "print(\"After move \", pallet_left_in_gripper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7204775-29c3-4abc-a172-c687e8a85500",
   "metadata": {},
   "source": [
    "These are the main use cases today.\n",
    "\n",
    "\n",
    "You can learn more in the [documentation](http://docs.corp.vicarious.com/master/platform/gaia/doc/overview.html) and [tests]()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49adac59-f367-47fd-a719-672d94ced363",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Interactions with Robot Planning Scene (RPS), GeometricScene?\n",
    "\n",
    "These are more specialized world models - they care only about a subset of the information (e.g. planning geometry) and need extra functionality (e.g. fast collision checking).\n",
    "\n",
    "\n",
    "They will be directly instantiatable from a Gaia instance (directly in C++)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e347a-92f0-4cbc-bea8-2339d83ba271",
   "metadata": {},
   "source": [
    "## Future\n",
    "\n",
    "- In the (very) near future: query `<sensor>` and automatically configure Ignition cameras from SDF. Visualize sensor frames and frustrum (where applicable) in GV.\n",
    "- Dynamic Gaia: a live view of all geometry animated with joint updates, model moves. One server with client instances that get (configurable) updates. Also still possble to have stand alone instances for subsets of data you care about (Mini Gaia).\n",
    "- Instantiate `RobotPlanningScene` directly from Gaia. Pick your slice of interest (e.g. robot x and everything within three meters around it).\n",
    "- SDF layering: One layer to represent physical systems, other layers for application specific information such as workspaces and special frames (e.g. a pregrasp frame)\n",
    "- Better tooling for SDF manipulation/templating. Currently we have an [`sdf`](https://github.com/vicariousinc/real_world/tree/master/common/sdf) library to do some very light work, but it doesn't completely support the current SDF version and the API is pretty unfriendly. Ideally we want something more friendly than XACRO for procedurally generated models and worlds.\n",
    "- Collision checking layer (much like how `GV` is a layer on top of the core Gaia data structures), which will give us much more control over the API and backend (e.g. [FCL](https://github.com/flexible-collision-library/fcl), [Bullet](https://pybullet.org/Bullet/BulletFull/classbtCollisionWorld.html), which versions to use) than with RobotPlanningScene, which is rooted in [MoveIt!](https://moveit.ros.org/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db685753-f2cf-47b1-ad00-1a1c69f3db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A rough overview of SDF / Gaia dataflow.\n",
    "SVG(filename=\"data_flow.dio.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3839c51-ed90-423a-9cc7-352129867342",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "- SDF specification. What is a [`<model>`](http://sdformat.org/spec?ver=1.8&elem=model)? What is a [`<link>`](http://sdformat.org/spec?ver=1.8&elem=link)? Read it here.\n",
    "- SDFormat features: \n",
    "    - [Collisions and Visuals](http://sdformat.org/tutorials?tut=spec_shapes&cat=specification&). \n",
    "    - [Pose Frame Semantics](http://sdformat.org/tutorials?tut=pose_frame_semantics_proposal&cat=pose_semantics_docs&). This devlves into detail into the differences with URDF.\n",
    "    - [Model composition](http://sdformat.org/tutorials?tut=composition_proposal&cat=pose_semantics_docs&). Models can be composed out of other models. In the future this will allow us to eliminate most uses of XACRO, as it is often used for composition.\n",
    "    - [Custom SDF extensions](http://sdformat.org/tutorials?tut=custom_elements_attributes_proposal&cat=pose_semantics_docs&). Read this to understand the vicarious custom elements (see below).\n",
    "- [Vicarious custom SDF extensions](http://docs.corp.vicarious.com/master/common/sdf/doc/user/custom_sdf_elements.html)\n",
    "- [Gaia documentation](http://docs.corp.vicarious.com/master/platform/gaia/doc/overview.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
